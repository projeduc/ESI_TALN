% !TEX TS-program = xelatex
% !TeX program = xelatex
% !TEX encoding = UTF-8
% !TEX spellcheck = fr

%=====================================================================
\ifx\wholebook\relax\else
	\documentclass{KodeBook}
	\input{calls}
	\begin{document}
		\mainmatter
	
\fi
%=====================================================================
\changegraphpath{../img/coherence/}
\chapter{Cohérence du discours}

\begin{introduction}[LES LANGU\textcolor{white}{E}S]
	\lettrine{E}{n} lisant un texte, nous ne devons pas sentir une interruption dans l'enchaînement des idées.
	Nous ne devons pas sauter d'une idée à une autre dans le même paragraphe.
	Cela est appelé : la cohérence ; un texte cohérent doit garder la même idée ou passer à une autre idée en gardant une sorte de continuité.
	L'analyse de la cohérence nous permet de vérifier qu'un texte est facile à lire et à comprendre. 
	Plusieurs théories ont été proposées pour représenter les relations de cohérence et donc permettre son analyse.
	Dans ce chapitre, nous allons présenter quelques théories de cohérence ainsi que des méthodes pour l'analyser.
\end{introduction} 

Prenons le texte ``\expword{L'hiver est une des quatre saisons de l'année. Le rapport était bien exposé. La pluie est une des caractéristiques de cette saison. J'ai lu un rapport sur cette saison.}".
Nous pouvons comprendre chaque phrase à part ; mais, il est difficile de comprendre l'idée du texte. 
Il est clair que les phrases sont mal-ordonnées. 
Donc, comprendre les phrases à part n'est pas une condition suffisante afin de comprendre un discours ; il faut que ce dernier soit cohérent.
L'analyse de la cohérence peut aider dans plusieurs tâches :
\begin{itemize}
	\item Génération du texte : lorsque nous générons un texte automatiquement, il faut que les phrases soient cohérentes. 
	Un exemple plus simple est la génération des résumés automatiques par extraction. 
	Une fois les phrases importantes sont sélectionnées, nous devons les réordonner pour avoir un résumé cohérent. 
	Un exemple d'une méthode pour ordonner les phrases dans le contexte du résumé automatique est proposé par \citet{2019-oufaida-al}.
	\item Compréhension du texte : comme illustré par l'exemple précédent, nous ne pouvons pas bien comprendre un texte que lorsqu'il est cohérent.
	\item Évaluation du texte : nous pouvons utiliser l'analyse de la cohérence afin d'évaluer automatiquement les expressions écrites des enfants. 
	Aussi, nous pouvons l'utiliser comme outil d'aide de rédaction (Nous n'avons pas tombé sur un tel outil ; mais il peut être d'une grande utilité pour les écrivains).
	\item Détection de plagiat : lorsque nous copions et collons des parties de plusieurs origines, nous aurons un texte incohérent. 
\end{itemize}

%===================================================================================
\section{Relations de cohérence}
%===================================================================================

En général, les phrases proches se partagent quelques mots ou sens. 
Ce phénomène est appelé ``\optword{Cohésion lexicale}" où la relation entre deux phrases consécutives est la similarité lexicale ou sémantique.
Une autre façon de voir la cohérence est en se basant sur le sujet du texte ; les phrases d'un discours forment une seule entité (elles discutent le même sujet). 
Cela est appelé : ``\optword{Cohérence basée sur l'entité}" ; où la relation entre les phrase est le sujet. 
Parmi les théories dans cette direction, nous pouvons mentionner : Centering theory et Entity grid model. 
Dans cette section, nous allons présenter  des relations plus concrètes qui relient les phrases l'une à l'autre. 
Dans ce cas, nous parlons de la \optword{cohérence basée sur les relations}. 
Deux représentations du discours sont bien connues : \ac{rst} et \ac{pdtb}.

\vfill

\subsection{Rhetorical Structure Theory (RST)}

\keyword[R]{\ac{rst}} modélise le discours sous forme des relations entre deux unités (des phrases ou parties des phrases) : \optword{Noyau (N)} et \optword{Satellite (S)}. 
Le noyau est une unité indépendante, peut être interprétée indépendamment des autres unités du texte.
Le satellite est une unité dépendante, ne peut être interprétée qu'en utilisant le noyau. 
Chaque relation de cohérence est définie en se basant sur deux acteurs : \optword{Lecteur (L)} ; qui a lit le script et \optword{Scripteur (S)} ;  qui a rédigé le script. 
Elle fournit des restrictions sur le noyau, sur le satellite et/ou sur les deux. 
L'effet de la relation peut prendre lieu dans un ou les deux acteurs. 
Voici quelques définitions des relations \keyword[R]{\ac{rst}} \cite{2006-Cornish} :
\begin{itemize}
	\item \optword{Élaboration} :  S donne des informations additionnelles sur la situation présentée dans N
	\begin{itemize}
		\item \textbf{Contraintes sur N + S :} S présente des informations supplémentaires vis-à-vis de la situation ou de quelqu'aspect du thème présenté(e) dans N 
		\item \textbf{Effet :}  L reconnaît la situation présentée dans S comme fournissant des informations supplémentaires au sujet de N. 
		\item \textbf{Lieu de l'effet :} N + S
		\item Ex. \expword{[\textsubscript{N} L'examen est facile.] [\textsubscript{S} Il ne prend qu'une heur.]}
	\end{itemize}

	\item \optword{Évidence} :  S donne des informations additionnelles sur la situation présentée dans N dans le but de convincre L à accepter les informations de N
	\begin{itemize}
		\item \textbf{Contraintes sur N :} L pourra ne pas croire en N à un degré suffisant pour Sc
		\item \textbf{Contraintes sur S :} L croit S ou le trouve crédible
		\item \textbf{Contraintes sur N + S :} La compréhension de S par L augmente sa croyance en N
		\item \textbf{Effet :}  La croyance de L en N est effectivement augmentée
		\item \textbf{Lieu de l'effet :} N
		\item Ex. \expword{[\textsubscript{N} Kevin doit être ici.] [\textsubscript{S} Sa voiture est garée à l'extérieur.]}
	\end{itemize}

	\item \optword{Contraste} :  Une relation d'opposition entre deux noyaux
	\begin{itemize}
		\item \textbf{Contraintes sur N :} multi-noyaux
		\item \textbf{Contraintes sur N + N :} pas plus de deux noyaux ; les situations présentées dans ces deux noyaux sont (a) comprises comme les mêmes à beaucoup d'égards, (b) comprises comme différant par quelques aspects et (c) comparées par rapport à l'une ou plus d'une de ces différences
		\item \textbf{Effet :}  L reconnaît la comparabilité et les différences fournies par la comparaison effectuée
		\item \textbf{Lieu de l'effet :} noyaux multiples
		\item Ex. \expword{[\textsubscript{N} Il a voté "Non" à la nouvelle constitution.] [\textsubscript{N} Son frère a voté "Oui".]}
	\end{itemize}

	\item \optword{Antithèse} :  Une relation d'opposition entre N et S dans le but que L ait une attitude positive envers N
	\begin{itemize}
		\item \textbf{Contraintes sur N :} Sc a une attitude positive par rapport à la situation présentée dans N
		\item \textbf{Contraintes sur N + N :} es situations présentées dans N et S sont en opposition (cf. CONTRASTE)
		\item \textbf{Effet :}  L'attitude positive de L vis-à-vis de N est augmentée
		\item \textbf{Lieu de l'effet :} N
		\item Ex. \expword{[\textsubscript{N} J'ai défendu la République jeune;] [\textsubscript{S} Je ne l'abandonnerai pas maintenant que je suis vieux.]}
	\end{itemize}
\end{itemize}

Les relations \keyword[R]{\ac{rst}} peuvent être classifiées selon la distinction thématique/présentationnelle (voir le tableau \ref{tab:rst-class-lect}). 
Une relation est dite ``thématique" lorsque le lecteur peut l'identifier.
Elle est utilisée afin d'exprimer certains aspects de la thématique. 
Par contre, une  relation présentationnelle vise à augmenter une disposition chez le lecteur, comme le désir d'agir ou le degré de son attitude positive envers, ou croyance en, ou encore acceptation de la proposition noyau. 

\begin{table}[ht]
	\centering\small
\begin{tabular}{p{.3\textwidth}p{.3\textwidth}p{.3\textwidth}}
	\hline\hline
	\textbf{thématique} && \textbf{présentationnelle}\\
	\hline
	
	Élaboration
	
	Circonstance
	
	Problème-Solution
	
	Cause intentionnelle
	
	Résultat intentionnel
	
	Cause non-intentionnelle
	
	Résultat non-intentionnel
	
	& But
	
	Condition
	
	Interprétation
	
	Évaluation
	
	Reformulation
	
	Résumé
	
	Séquence
	
	Contraste
	&
	Motivation
	
	Antithèse
	
	Arrière-plan
	
	Facilitation
	
	Évidence (« indice »)
	
	Justification
	
	Concession\\
	\hline\hline
\end{tabular}
\caption[Classification des relations RST selon le point de vu lecteur]{Classification des relations RST selon le point de vu lecteur \cite{2006-Cornish}}
\label{tab:rst-class-lect}
\end{table}

Les relations de cohérence peuvent être classifiées selon le niveau de traitement du langage (voir le tableau \ref{tab:rst-niveau}).
La catégorie ``thématique" correspondait à la catégorie ``sémantique" dans cette classification. 
La catégorie ``présentationnelle" peut être divisée sur deux catégories : ``pragmatique" et ``textuelle".  

\begin{table}[ht]
	\centering\small
\begin{tabular}{p{.3\textwidth}p{.2\textwidth}p{.2\textwidth}p{.15\textwidth}}
	\hline\hline
	\textbf{Sémantique} && \textbf{Pragmatique} & \textbf{Textuelle} \\
	\hline
	
	Élaboration
	
	Circonstance
	
	Problème-Solution
	
	Cause intentionnelle
	
	Résultat intentionnel
	
	Cause non-intentionnelle
	
	Résultat non-intentionnel
	&
	But
	
	Condition
	
	Interprétation
	
	Évaluation
	
	Séquence
	
	Contraste
	
	&
	
	Motivation
	
	Antithèse
	
	Facilitation
	
	Évidence (« indice »)
	
	Justification
	
	Concession
	
	&
	
	Arrière-plan
	
	Reformulation
	
	Résumé\\
	\hline\hline
\end{tabular}
\caption[Classification des relations RST selon les niveaux de traitement du langage]{Classification des relations RST selon les niveaux de traitement du langage \cite{2006-Cornish}}
\label{tab:rst-niveau}
\end{table}

\subsection{Penn Discourse TreeBank (PDTB)}

\keyword[P]{\ac{pdtb}} est un dataset annoté avec un autre modèle de cohérence. 
Dans ce modèle, nous ne nous intéressons pas à la structure en arbre ; nous nous intéressons seulement aux relations binaires. 
Les unités en relation sont annotées comme arguments : ``ARG1" et ``ARG2". 
L'unité marquée par ``ARG2" est annotée par un connective du discours (explicitement ou implicitement). 
Le tableau \ref{tab:pdtb-connect} représente des statistiques sur les connectives et leurs sens.
Les connectives du discours peuvent être :
\begin{itemize}
	\item \optword{Conjonctions de subordination} :  
	temporelle (Ex., ``\expword{when}", ``\expword{as soon as}"), 
	causale (Ex., ``\expword{because}"), 
	concessive (Ex., ``\expword{although}", ``\expword{even though}"), 
	objectif (Ex., ``\expword{so that}", ``\expword{in order that}") et 
	conditionnelle (Ex., ``\expword{if}", ``\expword{unless}").
	
	\item \optword{Conjonctions de coordination} : ``\expword{and}", ``\expword{but}", ``\expword{or}".
	
	\item \optword{Conjonctives adverbiales} : des adverbes qui expriment une relation de discours entre des évènements ou des états. Ex., ``\expword{however}", ``\expword{therefore}", ``\expword{then}", etc.
	Des syntagmes prépositionnels sont inclus aussi dans cette classe. Ex. ``\expword{as a result}",
		``\expword{in addition}", ``\expword{in fact}", etc.
	
	\item \optword{Connectives implicites} :  identifiées entre deux phrases adjacentes qui ne sont pas reliées par des connectives explicites.
\end{itemize}

\begin{table}[ht]
	\centering\small
	\begin{tabular}{p{.1\textwidth}lp{.8\textwidth}}
		\hline\hline
		\textbf{Connective} && \textbf{Sens}\\
		\hline
		
		after && succession (523), succession-reason (50), other (4) \\
		since && reason (94), succession (78), succession-reason (10), other (2) \\
		when && Synchrony (477), succession (157), general (100), succession-reason (65), Synchrony-general (50),
		Synchrony-reason (39), hypothetical (11), implicit assertion (11), Synchrony-hypothetical (10), other
		(69) \\
		while && juxtaposition (182), Synchrony (154), Contrast (120), expectation (79), opposition (78), Conjunction
		(39), Synchrony-juxtaposition (26), Synchrony-Conjunction (21), Synchrony-Contrast(22), COMPARISON (18), Synchrony-opposition (11), other (31) \\
		meanwhile && Synchrony-Conjunction (92), Synchrony (26), Conjunction (25), Synchrony-juxtaposition (15),
		other(35)\\
		but && Contrast (1609), juxtaposition (636), contra-expectation (494), COMPARISTON (260), opposition
		(174), Conjunction (63), Conjunction-Pragmatic contrast (14), Pragmatic-contrast (14), other (32)
		however Contrast (254), juxtaposition (89), contra-expectation (70), COMPARISON (49), opposition (31),
		other (12)\\
		although && expectation (132), Contrast (114) juxtaposition (34), contra-expectation (21), COMPARISON (16),
		opposition (9), other (2)\\
		and && Conjunction (2543), List (210), result-Conjunction (138), result (38), precedence-Conjunction (30),
		juxtaposition (11), other(30)\\
		if && hypothetical (682), general (175), unreal present (122), factual present (73), unreal past (53), expectation (34), implicit assertion (29), relevance (20), other (31)\\
		\hline\hline
	\end{tabular}
	\caption[Quelques connectives et des statistiques sur leurs sens]{Quelques connectives et des statistiques sur leurs sens \cite{2008-prasad-al}}
	\label{tab:pdtb-connect}
\end{table}

Les relations \keyword[P]{\ac{pdtb}} sont divisées en quatre familles : temporelle, comparaison, contingence et extension. 
Chaque relation appartient à une famille d'une façon hiérarchique comme indiqué dans la figure \ref{fig:pdtb-rel}. 
Par exemple, la relation de succession indiquée par des connectives comme ``after" est une relation synchrone qui est à son tour une relation temporelle.

\begin{figure}[!ht]
	\centering
\begin{minipage}{.3\textwidth}
	\scriptsize\bfseries
\begin{itemize}
	\item CONTINGENCY
	\begin{itemize}
		\item Cause
		\begin{itemize}
			\item Reason
			\item Result
		\end{itemize}
		\item Pragmatic Cause
		\begin{itemize}
			\item Justification
		\end{itemize}
		\item Condition
		\begin{itemize}
			\item Hypothetical
			\item General
			\item Unreal Present
			\item Unreal Past
			\item Factual Present
			\item Factual Past
		\end{itemize}
		\item Pragmatic Condition
		\begin{itemize}
			\item Relevance
			\item Implicit Assertion
		\end{itemize}
	\end{itemize}
\end{itemize}
\end{minipage}
\begin{minipage}{.3\textwidth}
	\scriptsize\bfseries
\begin{itemize}
	\item TEMPORAL
	\begin{itemize}
		\item Asynchronous
		\item Synchronous
		\begin{itemize}
			\item Precedence
			\item Succession
		\end{itemize}
	\end{itemize}
	\item COMPARISON
	\begin{itemize}
		\item Contrast
		\begin{itemize}
			\item Juxtaposition 
			\item Opposition
		\end{itemize}
		\item Pragmatic Contrast
		\item Concession
		\begin{itemize}
			\item Expectation
			\item Contra-expectation
		\end{itemize}
		\item Pragmatic Concession
	\end{itemize}
\end{itemize}
\end{minipage}
\begin{minipage}{.3\textwidth}
	\scriptsize\bfseries
	\begin{itemize}
		\item EXPANSION
		\begin{itemize}
			\item Conjunction
			\item Instantiation
			\item Restatement
			\begin{itemize}
				\item Specification
				\item Equivalence
				\item Generalization
			\end{itemize}
			\item Alternative
			\begin{itemize}
				\item Conjunction
				\item Disjunction
				\item Chosen Alternative
			\end{itemize}
			\item Exception
			\item List
		\end{itemize}
	\end{itemize}
\end{minipage}\vspace{-0.5cm}
	\caption[Hiérarchie des sens dans PDTB]{Hiérarchie des sens dans PDTB \cite{2008-prasad-al}}
	\label{fig:pdtb-rel}
\end{figure}



%\begin{figure}[ht]
%	\centering
%	\hgraphpage[.6\textwidth]{pdtb-sens_.pdf}
%	\caption{Hiérarchie des sens dans PDTB \cite{2008-prasad-al}}
%	\label{fig:pdtb-rel}
%\end{figure}



%===================================================================================
\section{Analyse basée structure de discours}
%===================================================================================

Un discours est cohérent s'il existe des relations entre ses parties. 
Analyser un discours veut dire chercher une structure du texte.
Dans le cas de \keyword[R]{\ac{rst}}, cette structure est un arbre indiquant les relations de cohérence entre les différentes parties. 
Contrairement à \keyword[R]{\ac{rst}}, \keyword[P]{\ac{pdtb}} ne génère pas un arbre.
Plutôt, c'est un ensemble des relations binaires entre les parties du texte ; surtout les phrases consécutives. 


\subsection{Analyse RST}

L'analyse \keyword[R]{\ac{rst}} consiste à construire un arbre de relations de cohérence entre les parties d'un texte. 
Cette tâche passe par deux étapes : détection des unités élémentaires de discours et classification des relations. 
La figure \ref{fig:rst-exp} représente une analyse \keyword[R]{\ac{rst}} d'un texte.
Nous remarquons que l'unité n'est pas toujours une phrase, mais elle peut être une partie d'une phrase (une clause).

\begin{figure}[!ht]
	\centering
	\hgraphpage[0.5\textwidth]{RST-arbre.pdf}
	\caption{Exemple d'un arbre RST}
	\label{fig:rst-exp}
\end{figure}

\subsubsection{Détection des unités élémentaires}

Une unité élémentaire de discours, en anglais \ac{edu}, est une phrase ou une clause de la phrase qui représente un sens. 
Exemple d'un texte divisé en \ac{edu} : \expword{[Mr. Rambo says]\textsubscript{e1} [that a 3.2-acre property]\textsubscript{e2} [overlooking the San Fernando Valley]\textsubscript{e3} [is priced at \$4 million]\textsubscript{e4} [because the late actor Erroll Flynn once lived there.]\textsubscript{e5}}. 
La détection des \ac{edu} consiste à trouver ces unités qui sont en général des clauses. 
Une des méthodes les plus anciennes utilise l'analyse syntaxique afin de trouver ces clauses. 
Des méthodes statistiques peuvent être utilisées afin de détecter les limites des \ac{edu}s. 
Comme caractéristiques, nous pouvons utiliser les informations syntaxiques et des indices de surface. 
Ce problème peut être vu comme annotation des séquences. 
Dans \cite{2018-wang-al}, les auteurs ont proposé un système neuronal\footnote{EDU avec réseau de neurones : \url{https://github.com/PKU-TANGENT/NeuralEDUSeg} [visité le 2021-09-15]} qui utilise le \keyword[E]{embedding} des mots. 
La figure \ref{fig:edu-embedding} représente leur architecture où l'entrée est une concaténation entre deux \keywordpl[E]{embedding} : \keyword[G]{GloVe} et \keyword[B]{BERT}. 
Nous utilisons un réseau \keyword[B]{Bi-LSTM} afin d'avoir le contexte en avant et en arrière pour chaque mot. 
Ensuite, chaque mot est classé comme : début d'un \ac{edu} (1) ou continuation d'un \ac{edu} (0). 

\begin{figure}[!ht]
	\centering
	\hgraphpage[.4\textwidth]{EDU_seg.pdf}
	\caption[Segmentation en EDUs par embeddings]{Segmentation en EDUs proposée par \citet{2018-wang-al} ; figure inspirée de \cite{2019-jurafsky-martin}}
	\label{fig:edu-embedding}
\end{figure}
%\begin{figure}[!ht]
%	\centering
%	\hgraphpage[.6\textwidth]{EDU_seg_.pdf}
%	\caption[Segmentation en EDUs par embeddings]{Segmentation en EDUs proposée par \citet{2018-wang-al} ; figure prise de \cite{2019-jurafsky-martin}}
%	\label{fig:edu-embedding}
%\end{figure}

\subsubsection{Classification des relations}

Une fois les \acp{edu} sont extraits, nous devons les lier en utilisant des relations de cohérence. 
La méthode la plus utilisée pour trouver la structure \keyword[R]{\ac{rst}} est SHIFT-REDUCE.  
Celle-ci se base sur une machine abstraite ayant la configuration $C = (\sigma, \beta, A)$ où $\sigma$ est une pile, $\beta$ est le tampon (buffer) d'entrée et $A$ est la liste des arcs créés (relations). 
La figure \ref{fig:rst-shift-reduce} représente l'architecture de cette machine qui est similaire à celle utilisée dans l'analyse syntaxique des dépendances par transition. 
La différence est que cette machine utilise les \acp{edu} et pas les mots comme éléments d'analyse.
Au début, la pile est vide, la liste des relations est vide et le tampon d'entrée contient tous les \ac{edu} ordonnés d'où  $C_{initiale} = (\varnothing, w, \emptyset)$. 
A la fin, la pile et le tampon d'entrée doivent être vides d'où $C_{finale} = (\varnothing, \varnothing, A)$.

\begin{figure}[!ht]
	\centering
	\hgraphpage[.38\textwidth]{RST-transitions.pdf}
	\caption{Architecture SHIFT-REDUCE pour la résolution de la structure RST}
	\label{fig:rst-shift-reduce}
\end{figure}

Les opérations permises par cette machine sont :
\begin{itemize}
	\item \optword{Shift} : mettre le premier élément du buffer dans la pile
	\item \optword{Reduce}\textbf{(l, d)} : fusionne les deux sous-arbres supérieurs de la pile, où \textbf{l} est l'étiquette de relation de cohérence, et \textbf{d} est la direction de nucléarité : \textbf{d $ \in $ \{NN, NS, SN\}}.
	\item \optword{Pop Root} : enlever la racine de l'arbre final de la pile.
\end{itemize}
Un exemple d'une analyse \keyword[R]{\ac{rst}} en utilisant la méthode SHIFT-REDUCE est illustré das la figure \ref{fig:rst-shred-yu-al}.

\begin{figure}[!ht]
	\centering
	\hgraphpage{RST_exp_.pdf}
	
	\hgraphpage[.7\textwidth]{RST_SR_exp_.pdf}
	\caption[Exemple d'analyse RST en utilisant Shif-Reduce]{Exemple d'analyse RST en utilisant Shif-Reduce \cite{2018-yu-al}}
	\label{fig:rst-shred-yu-al}
\end{figure}

Le composant ``Oracle" doit être entraîné afin de décider l'opération suivante. 
Nous pouvons utiliser des caractéristiques afin d'entraîner un algorithme d'apprentissage comme nous avons vu dans l'analyse des dépendances (chapitre 5). 
Nous pouvons aussi utiliser les \keywordpl[E]{embedding} avec un réseau de neurone comme la méthode proposée dans \cite{2018-yu-al}\footnote{Embedding pour RST : \url{https://github.com/yunan4nlp/NNDisParser} [visité le 2021-09-15]}. 
Les auteurs proposent d'utiliser une architecture encodeur-décodeur afin de décider l'opération suivante. 
L'encodeur a comme but de représenter tous les \acp{edu} comme des vecteurs.
Le décodeur utilise les représentations de quelques \acp{edu} afin de décider l'opération suivante. 

Nous commençons par l'encodeur qui prend en entrée une représentation $x_i^w$ de chaque mot $w_i$. 
Cette représentation et la concaténation du \keyword[E]{embedding} du mot $w_i$ et de sa catégorie grammaticale $t_i$ comme indiqué par l'équation \ref{eq:rst-embedding-entree}
\begin{equation}\label{eq:rst-embedding-entree}
x_i^w = embedding(w_i) \oplus embedding(t_i)
\end{equation}
Les mots d'une phrase $w_1 w_2 \ldots w_m$ sont passés par un réseau récurrent \keyword[B]{Bi-LSTM} pour avoir une représentation séquentielle comme indiqué par l'équation \ref{eq:rst-embedding-seqrep}.
\begin{equation}\label{eq:rst-embedding-seqrep}
\{h_1^w, h_2^w, \ldots, h_m^w \} = biLSTM(\{x_1^w, x_2^w, \ldots, x_m^w \})
\end{equation}
Nous avons déjà sélectionné les \ac{edu}s ; donc nous savons chaque début et fin d'un \ac{edu}. 
Afin de représenter un \ac{edu} $\{w_s, w_{s+1}, \ldots, w_t \}$, nous cherchons le vecteur central des vecteurs représentant les mots qui lui composent comme indiqué dans l'équation \ref{eq:rst-embedding-edurep}
\begin{equation}\label{eq:rst-embedding-edurep}
x^e = \frac{1}{t-s+1} \sum_{k=s}^{t} h_k^w
\end{equation}
Une fois la représentation individuelle de chaque \ac{edu} $x_i^e$ est trouvée, on cherche leurs représentations séquentielles. 
Pour ce faire, nous utilisons un autre réseau récurrent \keyword[B]{Bi-LSTM} comme indiqué par l'équation \ref{eq:rst-embedding-eduseqrep}
\begin{equation}\label{eq:rst-embedding-eduseqrep}
\{h_1^e, h_2^e, \ldots, h_n^e \} = biLSTM(\{x_1^e, x_2^e, \ldots, x_n^e \})
\end{equation}

Le décodeur est une couche neuronale feed-forward $W$ qui vise à inférer l'action suivante $o$. 
En entrée, il prend la représentation séquentielle du premier UED dans le buffer $ h_{e}^{q0} $ et les représentations séquentielles des trois sous-arbres $i$ au sommet de la pile $h_{si}^{sbt}$. 
Le décodeur est représenté par l'équation \ref{eq:rst-embedding-dec}. 
\begin{equation}\label{eq:rst-embedding-dec}
o = W(h_{s0}^{sbt} \oplus h_{s1}^{sbt} \oplus h_{s2}^{sbt} \oplus h_{q0}^{e})
\end{equation}
Un sous arbre peut être représenté par plusieurs \ac{edu}s $ s= \{e_i, \ldots, e_j\}$. 
Sa représentation peut être calculée par la moyenne des représentations des UEDs couverts, comme indiqué dans l'équation \ref{eq:rst-embedding-sousarbre}. 
\begin{equation}\label{eq:rst-embedding-sousarbre}
h_{s}^{sbt} = \frac{1}{j-i+1} \sum_{k=i}^{j} h_k^e
\end{equation}

\subsection{Analyse PDTB}

Dans l'analyse \ac{pdtb}, nous essayons de séparer les parties du texte et les annoter deux à deux par : ``ARG1" et ``ARG2". 
Dans la partie annotée par ``ARG2", nous essayons de l'annoter par une connective. 
Nous avons vu qu'il y a deux types de connectives : explicites (existantes dans le texte) et implicites (que nous puissions inférer). 
Dans le cas des connectives explicites, nous pouvons facilement les chercher et les trouver en utilisant leur liste. 
Mais, il existe des connectives qui ne représentent pas des relations de cohérence. 
Pour résoudre ce problème, nous pouvons utiliser un algorithme de désambigüisation qui classe une connective donnée comme : discours ou non. 
Une fois une connective est marquée comme discours, nous marquons la partie le contenant comme ``ARG2". 
Nous cherchons la partie en relation ``ARG1" en utilisant un algorithme d'apprentissage automatique. 
L'algorithme prend ``ARG2" et une autre partie adjacente comme entrée et comme sortie il estime si elles sont en relation ou non. 
Ensuite, nous marquons la relation entre les deux en utilisant la connective. 

Dans le cas où la connective est implicite, nous devons l'inférer étant donnée deux parties sans connectives. 
Une méthode est d'utiliser \keyword[B]{BERT} avec les parties séparées par ``[SEP]" comme entrée. 
Dans la sortie ``[CLS]", nous attachons un réseau de neurones à propagation avant afin d'inférer la connective.
Une autre méthode similaire est l'utilisation de deux réseaux \keyword[L]{LSTM} pour représenter chacune des deux parties. 
Cette méthode a été proposée par \citet{2020-liang-al}, où l'architecture est illustrée dans la figure \ref{fig:pdtb-liang}.
Le ``Max-Pool" est utilisé sur les représentations récurrentes des mots afin de composer le sens d'une partie et aussi pour réduire les paramètres du modèle.
Dans chaque position dans les vecteurs des mots, il prend le nombre max pour avoir un autre vecteur de même taille.

\begin{figure}[!ht]
	\centering
	\hgraphpage[.6\textwidth]{PDTB_exp_.pdf}
	\caption[Architecture pour la détection de relations PDTB implicites]{Architecture pour la détection de relations PDTB implicites \cite{2020-liang-al}}
	\label{fig:pdtb-liang}
\end{figure}

%===================================================================================
\section{Analyse basée sur l'entité de discours}
%===================================================================================

Un discours est cohérent s'il discute le même sujet.
Ce dernier peut être représenté par une entité. 
Quelque soit sa position dans le discours, cette entité doit rester la plus importante.
Prenons l'exemple ``\expword{John went to his favorite music store to buy a piano [John]. He had frequented the store for many years [John]. He was excited that he could finally buy a piano [John]. He arrived just as the store was closing for the day [John].}". 
Dans cet exemple, l'entité centrale de chaque phrase est ``John". 
Maintenant, prenons l'exemple : ``\expword{John went to his favorite music store to buy a piano [John]. It was a store John had frequented for many years [The store]. He was excited that he could finally buy a piano [John]. It was closing just as John arrived [The store].}".
Nous pouvons sentir que le texte est absurde ; il est un peut difficile à comprendre. 
Cela est dû au fait que l'entité centrale se bascule entre les phrases ; des fois ``John", d'autres ``The store". 
Dans cette section, nous allons discuter deux théories/méthodes pour analyser un texte en se basant sur l'entité et pas la structure.

\subsection{Centering theory}

Nous avons vu que les phrases (énoncés) doivent maintenir la même entité centrale. 
Cette intuition est réalisée dans cette théorie en maintenant deux représentations pour chaque énoncé $U_n$.
La première est l'entité saillante actuelle ; celle sur laquelle se concentre le discours dans l'énoncé $ U_{n-1} $.
Elle s'appelle ``\optword{Backward-looking center}" (centre rétrospectif), et elle est dénotée par $C_b(U_n)$. 
La deuxième est un ensemble des entités potentiellement saillantes dans le futur ; celles candidates pour être $C_b(U_{n+1})$.
Il s'appelle ``\optword{Forward-looking center}" (centres prospectifs), et il est dénoté par $C_f(U_n)$. 
Nous notons les entités de cet ensemble en se basant sur leurs rôles grammaticaux (sujet plus important que l'objet qui est plus important que le reste), l'ordre (En Arabe, ce qui est en premier est plus important), etc.
L'entité avec le plus grand score est choisie comme candidate pour être $C_b(U_{n+1})$.
Elle s'appelle ``\optword{Prefered center}" (centre préféré), et elle est dénotée par $C_p(U_n)$. 

Cette théorie se base sur l'hypothèse que le discours est plus facile à traiter lorsque les énoncés successifs parlent de la même entité. 
Cette hypothèse est formalisée comme une classification des énoncés selon la transition qu'ils induisent dans le centre local.
Il existe trois types de transitions \cite{2004-poesio-al} selon l'ordre de la plus cohérente : 
\begin{itemize}
	\item \optword{CONTINUE} : le locuteur parle d'une entité et il a l'intention d'en parler en futur
	\item \optword{RETAIN} : le locuteur parle d'une entité et il a l'intention d'en changer en futur
	\item \optword{SHIFT} : le locuteur a changé l'entité centrale
	\begin{itemize}
		\item \textbf{Smooth-SHIFT} : après le changement, il a l'intention d'en parler en futur
		\item \textbf{Rough-SHIFT} : après le changement, il a l'intention d'en changer en futur
	\end{itemize}
\end{itemize}

La théorie de centralité (Centering theory) se base sur deux règles. 
La première règle annonce que si un élément de $C_f(U_n)$ soit réalisé par un pronom dans l'énoncé suivant ($U_{n+1}$) alors $C_b(U_{n+1})$ devrait être réalisée par un pronom. 
L'intuition, ici, est que la pronominalisation est un moyen courant pour marquer la saillance du discours. 
S'il y a plusieurs pronoms dans un énoncé réalisant des entités de l'énoncé précédent, l'un de ces pronoms doit
réaliser le centre en arrière $C_b$.
La deuxième règle concerne les transitions mentionnées précédemment, où ``CONTINU" est plus cohérente que ``RETAIN" que ``Smooth-SHIFT" que ``Rough-SHIFT".
Ces transitions sont calculée selon le tableau \ref{tab:center-trans}.
L'intuition de cette règle est que les discours qui continuent à se center sur la même entité sont plus cohérents que ceux qui basculent vers d'autres centres.

\begin{table}[!ht]
	\centering
	\begin{tabular}{p{.2\textwidth}p{.2\textwidth}p{.2\textwidth}}
		\hline\hline
		& \bfseries$\mathbf{C_b(U_n) = C_b(U_{n-1})}$
		
		OU $\mathbf{C_b(U_n) = NULL}$
		& \bfseries$\mathbf{C_b(U_n) \ne C_b(U_{n-1})}$\\
		\hline
		
		$\mathbf{C_b(U_n) = C_p(U_n)}$ &
		CONTINUE & Smooth-SHIFT\\
		
		$\mathbf{C_b(U_n) \ne C_p(U_n)}$ &
		RETAIN & Rough-SHIFT\\
		\hline\hline
	\end{tabular}
	\caption{Transitions de la théorie de centralité}
	\label{tab:center-trans}
\end{table}

Reprenons deux phrases de l'exemple précédent, et essayons de calculer la centralité
\begin{itemize}
	\item John went to his favorite music store to buy a piano. $U_1$
	\begin{itemize}
		\item $C_b(U_1)$ = NULL
		\item $C_f(U_1)$ = \{John, music store, piano\}
		\item $C_p(U_1)$ = John (le sujet)
	\end{itemize}
	\item It was a store John had frequented for many years. $U_2$
	\begin{itemize}
		\item $C_b(U_2)$ = John
		\item $C_f(U_2)$ = \{(music) store, John, years\}
		\item $C_p(U_2)$ =  music store (sujet)
		\item $C_b(U_2) \ne C_p(U_2) \wedge C_b(U_2) \ne C_b(U_1) \Rightarrow$ Rough-SHIFT
	\end{itemize}
	\item He was excited that he could finally buy a piano. $U_3$
	\begin{itemize}
		\item $C_b(U_3)$ = music store
		\item $C_f(U_3)$ = \{John, piano\}
		\item $C_p(U_3)$ =  John (sujet)
		\item $C_b(U_3) \ne C_p(U_3) \wedge C_b(U_3) \ne C_b(U_2) \Rightarrow$ Rough-SHIFT
	\end{itemize}
\end{itemize}


\subsection{Entity Grid model}

Dans le modèle ``entity grid", un document est représenté par une matrice où les phrases représentent les lignes et les entités représentent les colonnes. 
Chaque cellule de cette matrice contient la fonction grammaticale de l'entité dans la phrase : sujet (s), objet (o), Autre (x) ou l'entité n'existe pas (\_). 
La figure \ref{fig:entity-grid-rep} représente un texte et sa représentation phrases/entités selon le modèle ``entity grid". 

\begin{figure}[!ht]
	\centering\footnotesize
	\begin{minipage}{.8\textwidth}
	\begin{enumerate}
		\item\ [The Justice Department]\textsubscript{s} is conducting an [anti-trust trial]\textsubscript{o} against [Microsoft Corp.]\textsubscript{x} with [evidence]\textsubscript{x} that [the company]\textsubscript{s} is increasingly attempting to crush [competitors]\textsubscript{o}.
		\item\ [Microsoft]\textsubscript{o} is accused of trying to forcefully buy into [markets]\textsubscript{x} where [its own products]\textsubscript{s} are not competitive enough to unseat [established brands]\textsubscript{o}.
		\item\ [The case]\textsubscript{s} revolves around [evidence]\textsubscript{o} of [Microsoft]\textsubscript{s} aggressively pressuring [Netscape]\textsubscript{o} into merging [browser software]\textsubscript{o}.
		\item\ [Microsoft]\textsubscript{s} claims [its tactics]\textsubscript{s} are commonplace and good economically.
		\item\ [The government]\textsubscript{s} may file [a civil suit]\textsubscript{o} ruling that [conspiracy]\textsubscript{s} to curb [competition]\textsubscript{o} through [collision]\textsubscript{x} is [a violation of the Sherman Act]\textsubscript{o}.
		\item\ [Microsoft]\textsubscript{s} continues to show [inscreased earnings]\textsubscript{o} despite [the trial]\textsubscript{x}.
	\end{enumerate}
	\end{minipage}
	
	\begin{tabular}{ccccccccccccccccc}
		& \rotatebox[origin=c]{90}{Department} & \rotatebox[origin=c]{90}{Trial} & \rotatebox[origin=c]{90}{Microsoft} &
		\rotatebox[origin=c]{90}{Evidence} & \rotatebox[origin=c]{90}{Competitors} & \rotatebox[origin=c]{90}{Markets} &
		\rotatebox[origin=c]{90}{Products} & \rotatebox[origin=c]{90}{Brands} & \rotatebox[origin=c]{90}{Case} &
		\rotatebox[origin=c]{90}{Netscape} & \rotatebox[origin=c]{90}{Software} & \rotatebox[origin=c]{90}{Tactics} &
		\rotatebox[origin=c]{90}{Government} & \rotatebox[origin=c]{90}{Suit} & \rotatebox[origin=c]{90}{Earnings} & \\
		
		1. & s & o & s & x & o & - & - & - & - & - & - & - & - & - & - & 1. \\
		2. & - & - & o & - & - & x & s & o & - & - & - & - & - & - & - & 2. \\
		3. & - & - & s & o & - & - & - & - & s & o & o & - & - & - & - & 3. \\
		4. & - & - & s & - & - & - & - & - & - & - & - & s & - & - & - & 4. \\
		5. & - & - & - & - & - & - & - & - & - & - & - & - & s & o & - & 5. \\
		6. & - & x & s & - & - & - & - & - & - & - & - & - & - & - & o & 6. \\
		
	\end{tabular}
	
	\caption[Exemple de la représentation d'un document par entités]{Exemple de la représentation d'un document par entités ; figure reconstruite de \cite{2008-barzilay-lapata}}
	\label{fig:entity-grid-rep}
\end{figure}

%\begin{figure}[!ht]
%	\centering
%	\hgraphpage[.7\textwidth]{EGM_doc_exp_.pdf}
%	
%	\hgraphpage[.4\textwidth]{EGM_doc_rep_exp_.pdf}
%	\caption[Exemple de la représentation d'un document par entités]{Exemple de la représentation d'un document par entités \cite{2008-barzilay-lapata}}
%	\label{fig:entity-grid-rep}
%\end{figure}

Un document est considéré comme cohérent s'il suit une certaine forme de pattern.
Ce pattern peut-être représenté par les fréquences de transitions grammaticales. Ex. ``\expword{ss, so, sx, s\_, os, oo, ox, o\_, ...}".
Dans l'exemple précédent, la transition ``s\_" a une fréquence de 6.
Un document peut être représenté par les probabilités des transitions grammaticales.
Une probabilité est le ratio entre le nombre d'une transition et le nombre de toutes les transitions.
Dans l'exemple précédent : \expword{P(s\_) = 6/75}.
Le tableau \ref{tab:entity-grid-prob} représente les probabilités des transitions de longueur 2 du document précédent.
%La figure \ref{fig:entity-grid-prob} représente les probabilités des transitions de longueur 2 du document précédent.

\begin{table}[ht]
	\centering
	\begin{tabular}{lllllllllllllllll}
		\hline
		& s s & s o & s x & s - & o s & o o & o x & o - & x s & x o & x x & x - & - s & - o & - x & - - \\
		\hline
		d1 & .01 & .01 & .00 & .08 & .01 & .00 & .00 & .09 & .00 & .00 & .00 & .03 & .05 & .07 & .03 & .59 \\
		d2 & .02 & .01 & .01 & .02 & .00 & .07 & .00 & .02 & .14 & .14 & .06 & .04 & .03 & .07 & .01 & .36 \\
		d3 & .02 & .00 & .00 & .03 & .09 & .00 & .09 & .06 & .00 & .00 & .00 & .05 & .03 & .07 & .17 & .39 \\
		\hline
	\end{tabular}
	\caption[Exemple de la représentation des documents par transitions grammaticales]{Exemple de la représentation des documents par transitions grammaticales \cite{2008-barzilay-lapata}}
	\label{tab:entity-grid-prob}
\end{table}
%\begin{figure}[!ht]
%	\centering
%	\hgraphpage[.8\textwidth]{EGM_doc_vec_exp_.pdf}
%	\caption[Exemple de la représentation des documents par transitions grammaticales]{Exemple de la représentation des documents par transitions grammaticales \cite{2008-barzilay-lapata}}
%	\label{fig:entity-grid-prob}
%\end{figure}

Afin de juger qu'un texte soit cohérent, nous utilisons un algorithme d'apprentissage automatique où les probabilités des transitions grammaticales sont utilisées comme caractéristiques. 
Le modèle d'apprentissage peut être entraîné à attribuer des scores selon le niveau de cohérence.
Dans ce cas, un texte non cohérent doit avoir un score inférieur à un autre cohérent.
Le problème qui se pose : il est difficile d'avoir beaucoup de textes annotés pour entraîner le système.
Une solution est d'utiliser une méthode auto-supervisée ; créer un texte non cohérent à partir d'un texte cohérent. 
Ceci peut être accompli en appliquant un ordre aléatoire des phrases d'un texte cohérent. 

Cette idée peut être utilisée pour tester les systèmes d'analyse de la cohérence : un texte cohérent doit avoir un score plus grand qu'un autre non cohérent. 
Donc, nous pouvons prendre un texte cohérent (les romans, etc.) et créer un autre non cohérent selon une de ces techniques :
\begin{itemize}
	\item Discrimination de l'ordre des phrases : ordre aléatoire des phrases et comparaison du score de cohérence avec celui de l'ordre original.
	\item Insertion de la phrase : modifier l'ordre d'une seule phrase et comparaison du score de cohérence avec celui de l'ordre original.
	\item Reconstruction de l'ordre des phrases : apprendre à ordonner les phrases
\end{itemize}

\sectioni{Discussion}
%\begin{discussion}
Une phrase doit être bien formée ; ceci est garanti par la grammaire. 
Elle doit, aussi, avoir un sens ; ceci est garanti par la sémantique. 
Lorsque nous fusionnons plusieurs phrases qui ont un sens, ce n'est pas une garantie que ce texte soit compréhensible ou au moins naturel. 
Un texte doit être cohérent. 
Mais, c'est quoi la cohérence ? Comment elle peut être mesurée ?
Il existe plusieurs théories pour représenter la cohérence qui peuvent être classées en deux approches : basées sur la structure ou basées sur l'entité. 
Les phrases (ou les clauses) d'un texte forment une structure qui se base sur des relations de cohérence. 
Aussi, elles doivent discuter la même entité.
Les deux approches ont deux visions différentes ; qui sont complémentaires à mon avis. 
Afin de juger la cohérence d'un texte, il vaut mieux utiliser les deux afin de vérifier deux aspects différents.

%\end{discussion}

\sectioni{Ressources supplémentaires}

\subsubsection*{Exercices}

\begin{enumerate}
	\item ...
	
\end{enumerate}

%\subsubsection*{Tutoriels}
%
%Les tutoriels sont accessibles via le répertoire Github.

%\subsubsection*{TP : Analyse syntaxique CKY}

%\subsubsection*{Lab}

%=====================================================================
\ifx\wholebook\relax\else
% \cleardoublepage
% \bibliographystyle{../use/ESIbib}
% \bibliography{../bib/RATstat}
	\end{document}
\fi
%=====================================================================
